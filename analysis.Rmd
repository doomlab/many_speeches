---
title: "Many Speeches Analysis"
author: "Jason Geller, Erin M. Buchanan, Ryan Rhodes"
date: "Last Updated: `r Sys.Date()`"
output:
  html_document:
    toc: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=FALSE,
                      warning=FALSE)
```
# Introduction

This document contains the functions and code to analyze the data from the Many Speech Analyses Project. Because of the size of the audio files and how long it takes, we skip the extraction part here, however, all the files needed to reproduce this can be executed on your local computer or via the Code Ocean container. 


## Libraries

These libraries are required to complete the following analyses. 

```{r packages}
library(tidyverse)
library(rPraat)
library(here)
library(report) # magic for reporting
library(performance) # magic for model checks
library(lme4)
#devtools::install_github("usagi5886/PraatR")
library(PraatR)
library(Cairo) # save pdf figures
#remotes::install_github("Pakillo/grateful")
library(grateful) # cite the packages we use
library(MBESS)
library(report)
```

## Functions

```{r functions, eval=FALSE}
# source https://marissabarlaz.github.io/portfolio/praatfns/

create_praat_files <- function(absdir, pitch = TRUE, formant = TRUE, intensity = TRUE){
  
mydir <- list.files(absdir, "*.WAV", ignore.case = T, full.names = T)
mydirpitch=str_replace_all(mydir,fixed(".WAV", ignore_case = T), ".Pitch")
mydirpitchtier=str_replace_all(mydir,fixed(".WAV", ignore_case = T), ".PitchTier")
mydirformant=str_replace_all(mydir,fixed(".WAV", ignore_case = T), ".Formant")
mydirint=str_replace_all(mydir, fixed(".WAV", ignore_case = T), ".Intensity")
mydirinttier=str_replace_all(mydir,fixed(".WAV", ignore_case = T), ".IntensityTier")
mydirtable=str_replace_all(mydir,fixed(".WAV", ignore_case = T), ".FormantTable")
mydirall=cbind(mydir, mydirpitch, mydirpitchtier, mydirformant, mydirint, mydirinttier, mydirtable)
  

PitchArguments=list(0.001, #timestep
                    75,    #pitch floor
                    350)   #pitch ceiling

#to Intensity...
IntensityArguments=list(100, #Maximum Pitch
                    0)    #TimeStep
  
#to Formant...  
FormantArguments=list(0.001, #timestep
                    5,    #Maximum number of formants
                   5500,  #Maximum formant
                   0.025,  #Window length 
                   50)    #pre-emphasis from        

#to table
FormantTableArgs = list("no", #frame number
                 "yes", #include time
                 6, #number of time decimals
                 "no", #include intensity
                 3, #number of intensity decimals
                 "yes", #include number of formants
                 3, #number of frequency decimals
                 "yes")#include bandwidths


if (pitch == TRUE){
  
print("Creating all Pitch files, please wait patiently.")
apply(mydirall, 1,
     function(x) praat("To Pitch...", arguments = PitchArguments, input=x[1], 
      output=x[2], overwrite=TRUE))
  
print("Creating all PitchTier files, please wait patiently.")
apply(mydirall, 1, 
      function(x) praat( "Down to PitchTier", input=x[2], output=x[3], overwrite=TRUE, filetype="headerless spreadsheet" ))
}

if (intensity == TRUE){      
print("Creating all Intensity files, please wait patiently.")
  apply(mydirall, 1, 
     function(x) praat("To Intensity...", arguments = IntensityArguments, input=x[1], 
      output=x[5], overwrite=TRUE))

  print("Creating all IntensityTier files, please wait patiently.")
apply(mydirall, 1, 
     function(x) praat("Down to IntensityTier", input=x[5], 
      output=x[6], overwrite=TRUE, filetype="text"))
}

if (formant == TRUE){

  print("Creating all Formant files, please wait patiently.")
  apply(mydirall, 1, 
     function(x) praat( "To Formant (burg)...",arguments = FormantArguments,input = x[1], output = x[4], overwrite = TRUE)
  )

print("Creating all FormantTable files, please wait patiently.")
apply(mydirall, 1, function(x) praat( "Down to Table...",
       arguments = FormantTableArgs, 
       input=x[4],
       output=x[7],
       filetype="comma-separated", 
       overwrite = TRUE
))

}

}

get_acoustic_data <- function(absdir, tiername = "segment", numpoints = 10, pitch = TRUE, formant = TRUE, intensity = TRUE, remove_files = FALSE){

  mydir <- list.files(absdir, "*.WAV", ignore.case = T, full.names = T)
  alltextgrids2 = list()
  
for (j in 1:length(mydir)){
  
  print(paste("Currently processing file", mydir[j], "... Please wait patiently."))
  curwav <- mydir[j]
  curtext = str_replace(curwav, fixed(".WAV", ignore_case = T), ".TextGrid")
  curpitch = str_replace(curwav, fixed(".WAV", ignore_case = T), ".Pitch")
  curpitchtier = str_replace(curwav, fixed(".WAV", ignore_case = T), ".PitchTier")
  curint = str_replace(curwav, fixed(".WAV", ignore_case = T), ".Intensity")
  curinttier = str_replace(curwav, fixed(".WAV", ignore_case = T), ".IntensityTier")
  curformant = str_replace(curwav, fixed(".WAV", ignore_case = T), ".Formant")
  
  curformanttable = str_replace(curwav, fixed(".WAV", ignore_case = T), ".FormantTable")
  
  TextGridInfo = tg.read(curtext)
  CurTextGrid = data.frame(filename = mydir[j], 
                           tmin = TextGridInfo[[tiername]]$t1, 
                           tmax = TextGridInfo[[tiername]]$t2, 
                           label = TextGridInfo[[tiername]]$label) %>% filter(label !="")
  
  if (numpoints == 1){
    CurTextGrid = CurTextGrid %>% mutate(normtime = 0.5, acttimenorm = (tmin+tmax)/2)
  } else{
    
  CurTextGrid = CurTextGrid %>% mutate(RepNo = as.numeric(as.factor(tmin))) %>% group_by(tmin) %>% 
    mutate(normtime = list(seq(0.1,1.0,length.out = numpoints)),
           acttimenorm= list(seq(from = tmin, to = tmax, by = (tmax-tmin)/(numpoints-1)))) %>%
    unnest(cols = c(normtime, acttimenorm)) 
  }
  
  if (pitch ==TRUE){
  PitchTierInfo = pt.read(curpitchtier)
  
  mywhichptpitch = map_dbl(CurTextGrid$acttimenorm, function(x) which.min(abs(x - PitchTierInfo$t)))
  #CurTextGrid$F0Time = map_dbl(mywhichptpitch, function(x) PitchTierInfo$t[x])
  CurTextGrid$F0 = map_dbl(mywhichptpitch, function(x) PitchTierInfo$f[x])
    
  CurTextGrid = CurTextGrid %>% mutate(F0 = as.numeric(na_if(F0, "--undefined--")))
  
  if (remove_files==TRUE) file.remove(curpitch, curpitchtier)
  }
  
  if (intensity ==TRUE){
  IntensityTierInfo = it.read(curinttier)
  
  mywhichptint = map_dbl(CurTextGrid$acttimenorm, function(x) which.min(abs(x - IntensityTierInfo$t)))
  CurTextGrid$Intensity = map_dbl(mywhichptint, function(x) IntensityTierInfo$i[x])
  if (remove_files==TRUE) file.remove(curint, curinttier)
  
  }
  
  
  if (formant ==TRUE){
  #FormantInfo = formant.read(curformant)
  
  FormantInfo = suppressMessages(read_delim(curformanttable, delim = ","))
  
  
  mywhichptformant = map_dbl(CurTextGrid$acttimenorm, function(x) which.min(abs(x - FormantInfo$`time(s)`)))
  #CurTextGrid$FormantTime = map_dbl(mywhichptformant, function(x) FormantInfo$`time(s)`[x])
  CurTextGrid$F1 = map(mywhichptformant, function(x) FormantInfo$`F1(Hz)`[x])
  CurTextGrid$B1 = map(mywhichptformant, function(x) FormantInfo$`B1(Hz)`[x])
  CurTextGrid$F2 = map(mywhichptformant, function(x) FormantInfo$`F2(Hz)`[x])
  CurTextGrid$B2 = map(mywhichptformant, function(x) FormantInfo$`B2(Hz)`[x])
  CurTextGrid$F3 = map(mywhichptformant, function(x) FormantInfo$`F3(Hz)`[x])
  CurTextGrid$B3 = map(mywhichptformant, function(x) FormantInfo$`B3(Hz)`[x])
  CurTextGrid$F4 = map(mywhichptformant, function(x) FormantInfo$`F4(Hz)`[x])
  CurTextGrid$B4 = map(mywhichptformant, function(x) FormantInfo$`B4(Hz)`[x])
  CurTextGrid$F5 = map(mywhichptformant, function(x) FormantInfo$`F5(Hz)`[x])
  CurTextGrid$B5 = map(mywhichptformant, function(x) FormantInfo$`B5(Hz)`[x])
  
  
  CurTextGrid = CurTextGrid %>% mutate_at(.vars = c("F1", "B1","F2", "B2","F3", "B3","F4", "B4","F5", "B5"), .funs = ~ as.numeric(na_if(., "--undefined--")))
  if (remove_files==TRUE) file.remove(curformant, curformanttable)
  
  }
  
  
  
  
  alltextgrids2[[j]] = CurTextGrid
  #rm(CurTextGrid, curwav, curtable, curpitch, curtext, curpitchtier)
  }
  
  all_data_rPraat <- do.call("rbind", alltextgrids2)
  return(all_data_rPraat)
}
```

## Import and Process Data

This section creates the `praat` files to analyze intensity across the provided audio from the team. The TextGrid files are merged with this data to align at the utterance level. We chose to select the highest intensity points at the approximate millisecond level. The average time for trials was 3-5 seconds, and therefore we chose to go with more sensitivity by selection 5000 analysis points for intensity. 

```{r praat-calc, eval=FALSE}
absdir <- here::here("audio")

create_praat_files(absdir, pitch = FALSE, formant = FALSE, intensity = TRUE)

intensity_files <- get_acoustic_data(absdir, tiername = "Condition", 
                                     numpoints = 5000, pitch = FALSE, 
                                     formant = FALSE, intensity = TRUE, 
                            â€¹         remove_files = FALSE)

intensity_files$filename <- gsub(absdir, "", intensity_files$filename)
intensity_files$filename <- gsub("\\/", "", intensity_files$filename)
intensity_files$filename <- gsub(".wav", "", intensity_files$filename)
```

## Merge with Trial Information

We use the trial-lists data to merge in information about the typicality for each randomized trial for speakers. 

```{r trial-merge, eval=FALSE}
# grab the trial-lists folder
inputFolder <- here::here("trial-lists")

# find all the csv files within that folder 
listFiles <- list.files(path = inputFolder, 
                        pattern = "\\.csv$" , ignore.case = TRUE, 
                        full.names = T)

# import all csv files 
trial_list <- lapply(listFiles, read.csv)
trial_DF <- do.call(rbind, trial_list)

# merge with intensity files
intensity_files$unique_trial <- paste(intensity_files$filename, 
                                      intensity_files$RepNo, 
                                      sep = "_")
trial_DF$unique_trial <- paste(trial_DF$speaker, 
                               trial_DF$trial, 
                               sep = "_")

intensity_final <- merge(intensity_files, 
                         trial_DF, 
                         by = "unique_trial", 
                         all.x = T)
```

## Subset the Data

- First only collect the noun-focus trials 
- Pick the max intensity for each trial-speaker combination
- Ensure we have a proper number of total trials (15 trials by 2 repeats for each speaker)

```{r subset-data, eval=FALSE}

intensity_final <- read_csv(here::here("intensity_df.csv")) # load this is in

# just look at noun focus trials
intensity_DF <- subset(intensity_final, label == "NF")

# pick the max intensity for each trial 
intensity_DF <- intensity_DF %>% 
  group_by(unique_trial) %>% 
  mutate(max_intensity = max(Intensity)) %>% 
  ungroup() %>%
  filter(max_intensity == Intensity)

# remove duplicate max values
# the columns of the time selected are what's not repeating 
# but they have the same max values as the adjacent times
norm_columns <- grep("norm", colnames(intensity_DF))
intensity_DF <- intensity_DF[!duplicated(intensity_DF[ , -norm_columns ]), ]

# ensure information we have is good
# 15 sentences (trial) times 2 times each = 30 trials 
table(intensity_DF$filename)

# 15 sentences by 2 times by 30 people = 900 rows
nrow(intensity_DF)

# write out for others to check without praat
write.csv(intensity_DF, "intensity_df.csv", row.names = F)
```

## Analyze the Data

### Run the analysis:
  - Multilevel model using REML estimation with `nlme`
  - DV is peak intensity
  - IV is typicality treated as a continuous variable with `typ_mean` from trial list data
  - Random cross classified intercepts with participants nested in trials 
  - Random slope of typicality

```{r run-mlm}
# dv is intensity peak from trial
# participant level 1
# trial is level 2
# random slope of typicality as continuous variable
# fixed effects of typicality as continuous variable

intensity_final <- read_csv(here::here("intensity_df.csv")) # load this is in
# just look at noun focus trials
intensity_DF <- subset(intensity_final, label == "NF")


intensity_model_lmer <- lmer(Intensity ~ typ_mean + (1|target_name)+ (1|filename) + (1|filename:target_name),
                       data = intensity_DF)

summary(intensity_model_lmer)
```

### Results

```{r}
report(intensity_model_lmer)
```

### Effect Size

```{r}
ci.R2(1.31e-07, N = 900, p = .982)
```

### Assumption Checks

For the most part, it looks like the assumptions are met.

```{r model_performance}

performance::check_model(intensity_model_lmer)


ggsave(here::here("figures", "model_diagnostics.pdf"), width = 9, height = 8, device = cairo_pdf)
```

```{r}
cite_packages(output = "paragraph")
```



